{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10f526da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/menon/.local/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c2d5c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm,\n",
    "                          target_names=None,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=False):\n",
    "    \"\"\"\n",
    "    given a sklearn confusion matrix (cm), make a nice plot\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
    "\n",
    "    target_names: given classification classes such as [0, 1, 2]\n",
    "                  the class names, for example: ['high', 'medium', 'low']\n",
    "\n",
    "    title:        the text to display at the top of the matrix\n",
    "\n",
    "    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
    "                  see http://matplotlib.org/examples/color/colormaps_reference.html\n",
    "                  plt.get_cmap('jet') or plt.cm.Blues\n",
    "\n",
    "    normalize:    If False, plot the raw numbers\n",
    "                  If True, plot the proportions\n",
    "\n",
    "    Usage\n",
    "    -----\n",
    "    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n",
    "                                                              # sklearn.metrics.confusion_matrix\n",
    "                          normalize    = True,                # show proportions\n",
    "                          target_names = y_labels_vals,       # list of names of the classes\n",
    "                          title        = best_estimator_name) # title of graph\n",
    "\n",
    "    Citiation\n",
    "    ---------\n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import itertools\n",
    "\n",
    "    accuracy = np.trace(cm) / np.sum(cm).astype('float')\n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if target_names is None:\n",
    "        target_names = [i for i in range(cm.shape[0])]\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84a566bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transf_dados(name):\n",
    "    d = {}  # dictionary that will hold them \n",
    "\n",
    "    for i in range(1,24):  # loop over files\n",
    "        if i < 10: count = '0'+str(i)\n",
    "        else: count= str(i)\n",
    "\n",
    "        file_name = \"P\"+count+\"_\"+name\n",
    "        # read csv into a dataframe and add it to dict with file_name as it key\n",
    "        d[file_name] = pd.read_csv('dataset/'+file_name+'.csv')\n",
    "        \n",
    "    x_values =np.zeros(0)\n",
    "    y_values =np.zeros(0)\n",
    "    keys=[]\n",
    "    for key in d:\n",
    "        _len = len(d[key]['x'])\n",
    "        time_series = np.zeros((3,_len))\n",
    "        keys.append(key)\n",
    "\n",
    "    return d, keys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46de49c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1,keys1 = transf_dados('READ')\n",
    "d2,keys2 =transf_dados('SEARCH')\n",
    "\n",
    "d3,keys3 =transf_dados('BROWSE')\n",
    "d4,keys4 =transf_dados('DEBUG')\n",
    "d5,keys5 =transf_dados('INTERPRET')\n",
    "d6,keys6 =transf_dados('PLAY')\n",
    "d7,keys7 =transf_dados('WATCH')\n",
    "d8,keys8 =transf_dados('WRITE')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a598891",
   "metadata": {},
   "outputs": [],
   "source": [
    "D={}\n",
    "dd1 ={} \n",
    "dd2 ={}\n",
    "dd3 ={} \n",
    "dd4 ={}\n",
    "dd5 ={} \n",
    "dd6 ={}\n",
    "dd7 ={} \n",
    "dd8 ={}\n",
    "\n",
    "dd1['p01'] = d1['P01_READ']\n",
    "dd2['p01'] = d2['P01_SEARCH']\n",
    "\n",
    "dd3['p01'] = d3['P01_BROWSE']\n",
    "dd4['p01'] = d4['P01_DEBUG']\n",
    "\n",
    "dd5['p01'] = d5['P01_INTERPRET']\n",
    "dd6['p01'] = d6['P01_PLAY']\n",
    "\n",
    "dd7['p01'] = d7['P01_WATCH']\n",
    "dd8['p01'] = d8['P01_WRITE']\n",
    "\n",
    "D['READ'] = dd1\n",
    "D['SEARCH'] = dd2\n",
    "\n",
    "D['BROWSE'] = dd3\n",
    "D['DEBUG'] = dd4\n",
    "\n",
    "D['INTERPRET'] = dd5\n",
    "D['PLAY'] = dd6\n",
    "\n",
    "D['WATCH'] = dd7\n",
    "D['WRITE'] = dd8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "addd42af",
   "metadata": {},
   "outputs": [],
   "source": [
    "window =4\n",
    "lst_labels =[]\n",
    "lst_values =[]\n",
    "columns = {}\n",
    "\n",
    "\n",
    "for index in range(window):\n",
    "    label_x = \"x\"+str(index)\n",
    "    label_y = \"y\"+str(index)\n",
    "    lst_labels.insert(len(lst_labels), label_x)\n",
    "    lst_labels.insert(len(lst_labels), label_y)\n",
    "    columns['label_x'] = 'numeric'\n",
    "    columns['label_y'] = 'numeric'\n",
    "lst_labels.insert(len(lst_labels),'ROTULO')\n",
    "columns['ROTULO'] ='categorical'\n",
    "\n",
    "for atividade in D:\n",
    "    for pessoa in D[atividade]:\n",
    "        for j in range(1,5500,window):\n",
    "            lst_values_aux =[] \n",
    "            for i in range(window):\n",
    "                            \n",
    "                lst_values_aux.insert(len(lst_values_aux), D[atividade][pessoa]['x'][j+i])\n",
    "                lst_values_aux.insert(len(lst_values_aux), D[atividade][pessoa]['y'][j+i])\n",
    "\n",
    "            lst_values_aux.insert(len(lst_values_aux),atividade)\n",
    "            lst_values.insert(len(lst_values),lst_values_aux)\n",
    "            \n",
    "df2 = pd.DataFrame([lst_values[0]], columns = lst_labels)           \n",
    "for j in range(1,len(lst_values)):\n",
    "    newdf = pd.DataFrame([lst_values[j]], columns = lst_labels)               \n",
    "    df2 = pd.concat([df2, newdf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a023dfc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>y0</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>x3</th>\n",
       "      <th>y3</th>\n",
       "      <th>ROTULO</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.738480</td>\n",
       "      <td>0.523135</td>\n",
       "      <td>0.636020</td>\n",
       "      <td>0.638465</td>\n",
       "      <td>0.601935</td>\n",
       "      <td>0.482245</td>\n",
       "      <td>0.626700</td>\n",
       "      <td>0.525903</td>\n",
       "      <td>READ</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1375</th>\n",
       "      <td>0.651893</td>\n",
       "      <td>0.517610</td>\n",
       "      <td>0.531971</td>\n",
       "      <td>0.618840</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.403207</td>\n",
       "      <td>0.410795</td>\n",
       "      <td>0.502386</td>\n",
       "      <td>SEARCH</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2750</th>\n",
       "      <td>0.742882</td>\n",
       "      <td>0.510359</td>\n",
       "      <td>0.638668</td>\n",
       "      <td>0.625818</td>\n",
       "      <td>0.607515</td>\n",
       "      <td>0.469645</td>\n",
       "      <td>0.636588</td>\n",
       "      <td>0.517382</td>\n",
       "      <td>BROWSE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4125</th>\n",
       "      <td>0.549163</td>\n",
       "      <td>0.464088</td>\n",
       "      <td>0.390087</td>\n",
       "      <td>0.561710</td>\n",
       "      <td>0.359747</td>\n",
       "      <td>0.383734</td>\n",
       "      <td>0.323445</td>\n",
       "      <td>0.469666</td>\n",
       "      <td>DEBUG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5500</th>\n",
       "      <td>0.601702</td>\n",
       "      <td>0.535566</td>\n",
       "      <td>0.367764</td>\n",
       "      <td>0.663323</td>\n",
       "      <td>0.343378</td>\n",
       "      <td>0.528637</td>\n",
       "      <td>0.319324</td>\n",
       "      <td>0.478868</td>\n",
       "      <td>INTERPRET</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6875</th>\n",
       "      <td>0.499853</td>\n",
       "      <td>0.359116</td>\n",
       "      <td>0.320091</td>\n",
       "      <td>0.419102</td>\n",
       "      <td>0.321057</td>\n",
       "      <td>0.206186</td>\n",
       "      <td>0.313968</td>\n",
       "      <td>0.356510</td>\n",
       "      <td>PLAY</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8250</th>\n",
       "      <td>0.587907</td>\n",
       "      <td>0.714434</td>\n",
       "      <td>0.496406</td>\n",
       "      <td>0.872656</td>\n",
       "      <td>0.447917</td>\n",
       "      <td>0.816724</td>\n",
       "      <td>0.494850</td>\n",
       "      <td>0.723586</td>\n",
       "      <td>WATCH</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9625</th>\n",
       "      <td>0.639859</td>\n",
       "      <td>0.501036</td>\n",
       "      <td>0.444192</td>\n",
       "      <td>0.593982</td>\n",
       "      <td>0.419271</td>\n",
       "      <td>0.435281</td>\n",
       "      <td>0.416976</td>\n",
       "      <td>0.494888</td>\n",
       "      <td>WRITE</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            x0        y0        x1        y1        x2        y2        x3  \\\n",
       "0     0.738480  0.523135  0.636020  0.638465  0.601935  0.482245  0.626700   \n",
       "1375  0.651893  0.517610  0.531971  0.618840  0.464286  0.403207  0.410795   \n",
       "2750  0.742882  0.510359  0.638668  0.625818  0.607515  0.469645  0.636588   \n",
       "4125  0.549163  0.464088  0.390087  0.561710  0.359747  0.383734  0.323445   \n",
       "5500  0.601702  0.535566  0.367764  0.663323  0.343378  0.528637  0.319324   \n",
       "6875  0.499853  0.359116  0.320091  0.419102  0.321057  0.206186  0.313968   \n",
       "8250  0.587907  0.714434  0.496406  0.872656  0.447917  0.816724  0.494850   \n",
       "9625  0.639859  0.501036  0.444192  0.593982  0.419271  0.435281  0.416976   \n",
       "\n",
       "            y3     ROTULO  class  \n",
       "0     0.525903       READ      4  \n",
       "1375  0.502386     SEARCH      5  \n",
       "2750  0.517382     BROWSE      0  \n",
       "4125  0.469666      DEBUG      1  \n",
       "5500  0.478868  INTERPRET      2  \n",
       "6875  0.356510       PLAY      3  \n",
       "8250  0.723586      WATCH      6  \n",
       "9625  0.494888      WRITE      7  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "label =label_encoder.fit_transform(df2['ROTULO'])\n",
    "df2['class'] = label\n",
    "\n",
    "scaler_1 = MinMaxScaler()\n",
    "\n",
    "\n",
    "df2[lst_labels[:-1]] = scaler_1.fit_transform(df2[lst_labels[:-1]])\n",
    "df2 = df2.reset_index(drop=True)\n",
    "df2.groupby(['class']).head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f63c6f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame.to_numpy(df2[lst_labels[:-1]])\n",
    "Y = pd.Series.to_numpy(df2['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d49de221",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x, x_val, y, y_val = train_test_split(X, Y, test_size=0.33, random_state=42)\n",
    "x, x_test, y, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "x_test, x_val, y_test, y_val = train_test_split(x_test,y_test,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24003d1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8800, 8), (8800,), (440, 8), (440,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape, x_val.shape, y_val.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7a9cbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x.reshape(-1, x.shape[1]).astype('float32')\n",
    "y_train = y\n",
    "\n",
    "x_val = x_val.reshape(-1, x_val.shape[1]).astype('float32')\n",
    "y_val = y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92440b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b34a777",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(Dataset):\n",
    "    def __init__(self):\n",
    "        self.x=torch.from_numpy(x_train).float()\n",
    "        self.y=torch.from_numpy(y_train).long()\n",
    "        self.len=self.x.shape[0]\n",
    "    def __getitem__(self,index):      \n",
    "        return self.x[index], self.y[index]\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "class Data_ver(Dataset):\n",
    "    def __init__(self):\n",
    "        self.x_val=torch.from_numpy(x_val).float()\n",
    "        self.y_val=torch.from_numpy(y_val).long()\n",
    "        self.x_test=torch.from_numpy(x_test)\n",
    "        self.y_test=torch.from_numpy(y_test).long()\n",
    "        #self.len=self.x.shape[0]\n",
    "    def __getitem__(self,index):      \n",
    "        return self.x[index], self.y[index]\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad0c03ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set    = Data()\n",
    "ver_dataset  = Data_ver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3edff3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader=DataLoader(dataset=data_set,batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6133329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8800, 8]), torch.Size([8800]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set.x.shape, data_set.y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cbdaaa1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self,D_in,H,D_out):\n",
    "        super(Net,self).__init__()\n",
    "        self.linear1=nn.Linear(D_in,H)\n",
    "        self.linear2=nn.Linear(H,D_out)\n",
    "\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=torch.sigmoid(self.linear1(x))  \n",
    "        x=self.linear2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21986103",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b95424",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f88b04a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim=window*2   # how many Variables are in the dataset\n",
    "hidden_dim = 14 # hidden layers\n",
    "output_dim=8   # number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1357cd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model\n",
    "model=Net(input_dim,hidden_dim,output_dim)\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "learning_rate=0.1\n",
    "optimizer=torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94966a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▊                                          | 2/100 [00:07<06:24,  3.92s/it]"
     ]
    }
   ],
   "source": [
    "n_epochs=100\n",
    "#loss_list=[]\n",
    "batch_size=12\n",
    "loss_list     = np.zeros((n_epochs,))\n",
    "accuracy_list = np.zeros((n_epochs,))\n",
    "early_stop = False\n",
    "trigger_times =0\n",
    "patience =2\n",
    "for epoch in tqdm.trange(n_epochs):\n",
    "    for x, y in trainloader:\n",
    "      \n",
    "\n",
    "        #clear gradient \n",
    "        optimizer.zero_grad()\n",
    "        #make a prediction \n",
    "        z=model(x)\n",
    "        # calculate loss, da Cross Entropy benutzt wird muss ich in den loss Klassen vorhersagen, \n",
    "        # also Wahrscheinlichkeit pro Klasse. Das mach torch.max(y,1)[1])\n",
    "        loss=criterion(z,y)\n",
    "        # calculate gradients of parameters \n",
    "        loss.backward()\n",
    "        # update parameters \n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        loss_list[epoch] = loss.data\n",
    "        '''if epoch>10:\n",
    "            if loss_list[epoch]> round(loss_list[epoch-1],1):\n",
    "                trigger_times += 1\n",
    "                if trigger_times >= patience:\n",
    "                        print('Early stopping!\\nStart to test process.')\n",
    "                        early_stop = True\n",
    "                        break\n",
    "            else:\n",
    "                   # print('trigger times: 0')\n",
    "                    trigger_times = 0''' \n",
    "        \n",
    "    with torch.no_grad():\n",
    "        y_pred = model(ver_dataset.x_val)\n",
    "        correct = (torch.argmax(y_pred, dim=1) == ver_dataset.y_val).type(torch.FloatTensor)\n",
    "        accuracy_list[epoch] = correct.mean()\n",
    "    if early_stop == True:\n",
    "        final_epoch = epoch\n",
    "        break\n",
    "        #print('epoch {}, loss {}'.format(epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d7c9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model(ver_dataset.x_test.type(torch.FloatTensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc87e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, figsize=(12, 6), sharex=True)\n",
    "\n",
    "ax1.plot(accuracy_list[:epoch])\n",
    "ax1.set_ylabel(\"validation accuracy\")\n",
    "ax2.plot(loss_list[:epoch])\n",
    "ax2.set_ylabel(\"validation loss\")\n",
    "ax2.set_xlabel(\"epochs\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9348578",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_arr = y_pred.detach().numpy()\n",
    "original_arr = ver_dataset.y_test.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb7e41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pred_arr = np.zeros(len(pred_arr))\n",
    "for i in range(len(pred_arr)):\n",
    "    new_pred_arr[i] = np.argmax(pred_arr[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e319da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(original_arr, new_pred_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d135a9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(original_arr, new_pred_arr)\n",
    "\n",
    "plot_confusion_matrix(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09564c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"acc_lss_1.dat\", 'w+')\n",
    "for i in range(len(accuracy_list[:epoch])):\n",
    "    f.write('%f \\t %f \\t %f \\n'%(i,accuracy_list[i],loss_list[i]))\n",
    "f.close()\n",
    "\n",
    "np.savetxt(\"matrix.dat\", np.transpose(cm),fmt=\"%3.0f\",  delimiter='\\t ', newline='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90612f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
